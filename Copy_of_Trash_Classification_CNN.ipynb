{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "nHL-1Us43T8l"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import keras.utils as image\n",
    "from IPython.utils import io\n",
    "\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "import importlib\n",
    "import pathlib\n",
    "\n",
    "import requests\n",
    "from functools import partial\n",
    "\n",
    "size_ = (10,8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2009 files belonging to 6 classes.\n",
      "Using 1608 files for training.\n",
      "Found 518 files belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = image.image_dataset_from_directory(\n",
    "    '/home/sarp/DS5460/garbage_classifier/train/',\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=123,\n",
    "    image_size=(512,384),\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "test_ds = image.image_dataset_from_directory(\n",
    "    '/home/sarp/DS5460/garbage_classifier/test/',\n",
    "    seed=123,\n",
    "    image_size=(512,384),\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(32, 512, 384, 3), dtype=float32, numpy=\n",
       " array([[[[226.     , 229.     , 238.     ],\n",
       "          [226.     , 229.     , 238.     ],\n",
       "          [226.83333, 229.83333, 238.83333],\n",
       "          ...,\n",
       "          [183.     , 182.     , 187.     ],\n",
       "          [182.5    , 181.5    , 186.5    ],\n",
       "          [182.     , 181.     , 186.     ]],\n",
       " \n",
       "         [[226.     , 229.     , 238.     ],\n",
       "          [226.     , 229.     , 238.     ],\n",
       "          [226.3125 , 229.3125 , 238.3125 ],\n",
       "          ...,\n",
       "          [183.     , 182.     , 187.     ],\n",
       "          [182.5    , 181.5    , 186.5    ],\n",
       "          [182.     , 181.     , 186.     ]],\n",
       " \n",
       "         [[225.6875 , 228.6875 , 237.6875 ],\n",
       "          [226.     , 229.     , 238.     ],\n",
       "          [226.     , 229.     , 238.     ],\n",
       "          ...,\n",
       "          [183.     , 182.     , 187.     ],\n",
       "          [182.5    , 181.5    , 186.5    ],\n",
       "          [182.     , 181.     , 186.     ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[220.     , 222.     , 234.     ],\n",
       "          [220.     , 222.     , 234.     ],\n",
       "          [219.6875 , 221.6875 , 233.6875 ],\n",
       "          ...,\n",
       "          [128.375  , 127.375  , 123.375  ],\n",
       "          [129.25   , 128.25   , 124.25   ],\n",
       "          [131.89586, 130.89586, 126.89586]],\n",
       " \n",
       "         [[220.3125 , 222.3125 , 234.3125 ],\n",
       "          [220.     , 222.     , 234.     ],\n",
       "          [220.     , 222.     , 234.     ],\n",
       "          ...,\n",
       "          [128.     , 127.     , 123.     ],\n",
       "          [128.6875 , 127.6875 , 123.6875 ],\n",
       "          [130.20834, 129.20834, 125.20834]],\n",
       " \n",
       "         [[220.83333, 222.83333, 234.83333],\n",
       "          [220.     , 222.     , 234.     ],\n",
       "          [220.     , 222.     , 234.     ],\n",
       "          ...,\n",
       "          [128.     , 127.     , 123.     ],\n",
       "          [129.     , 128.     , 124.     ],\n",
       "          [130.83334, 129.83334, 125.83334]]],\n",
       " \n",
       " \n",
       "        [[[241.     , 242.     , 237.     ],\n",
       "          [241.     , 242.     , 237.     ],\n",
       "          [241.     , 242.     , 237.     ],\n",
       "          ...,\n",
       "          [226.     , 231.     , 225.     ],\n",
       "          [225.5    , 230.5    , 224.5    ],\n",
       "          [225.     , 230.     , 224.     ]],\n",
       " \n",
       "         [[241.     , 242.     , 237.     ],\n",
       "          [241.     , 242.     , 237.     ],\n",
       "          [241.     , 242.     , 237.     ],\n",
       "          ...,\n",
       "          [226.     , 231.     , 225.     ],\n",
       "          [225.5    , 230.5    , 224.5    ],\n",
       "          [225.     , 230.     , 224.     ]],\n",
       " \n",
       "         [[241.     , 242.     , 237.     ],\n",
       "          [241.     , 242.     , 237.     ],\n",
       "          [241.     , 242.     , 237.     ],\n",
       "          ...,\n",
       "          [226.     , 231.     , 225.     ],\n",
       "          [225.5    , 230.5    , 224.5    ],\n",
       "          [225.     , 230.     , 224.     ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[234.     , 239.     , 232.     ],\n",
       "          [234.     , 239.     , 232.     ],\n",
       "          [234.     , 239.     , 232.     ],\n",
       "          ...,\n",
       "          [214.     , 219.     , 213.     ],\n",
       "          [214.     , 219.     , 213.     ],\n",
       "          [214.     , 219.     , 213.     ]],\n",
       " \n",
       "         [[234.     , 239.     , 232.     ],\n",
       "          [234.     , 239.     , 232.     ],\n",
       "          [234.     , 239.     , 232.     ],\n",
       "          ...,\n",
       "          [214.     , 219.     , 213.     ],\n",
       "          [214.     , 219.     , 213.     ],\n",
       "          [214.     , 219.     , 213.     ]],\n",
       " \n",
       "         [[234.     , 239.     , 232.     ],\n",
       "          [234.     , 239.     , 232.     ],\n",
       "          [234.     , 239.     , 232.     ],\n",
       "          ...,\n",
       "          [214.     , 219.     , 213.     ],\n",
       "          [214.     , 219.     , 213.     ],\n",
       "          [214.     , 219.     , 213.     ]]],\n",
       " \n",
       " \n",
       "        [[[222.     , 226.     , 237.     ],\n",
       "          [222.     , 226.     , 237.     ],\n",
       "          [222.     , 226.     , 237.     ],\n",
       "          ...,\n",
       "          [186.     , 189.     , 196.     ],\n",
       "          [186.     , 189.     , 196.     ],\n",
       "          [186.     , 189.     , 196.     ]],\n",
       " \n",
       "         [[222.     , 226.     , 237.     ],\n",
       "          [222.     , 226.     , 237.     ],\n",
       "          [222.     , 226.     , 237.     ],\n",
       "          ...,\n",
       "          [186.     , 189.     , 196.     ],\n",
       "          [186.     , 189.     , 196.     ],\n",
       "          [186.     , 189.     , 196.     ]],\n",
       " \n",
       "         [[222.     , 226.     , 237.     ],\n",
       "          [222.     , 226.     , 237.     ],\n",
       "          [222.     , 226.     , 237.     ],\n",
       "          ...,\n",
       "          [186.     , 189.     , 196.     ],\n",
       "          [186.     , 189.     , 196.     ],\n",
       "          [186.     , 189.     , 196.     ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[233.     , 236.     , 245.     ],\n",
       "          [233.     , 236.     , 245.     ],\n",
       "          [232.6875 , 235.6875 , 244.6875 ],\n",
       "          ...,\n",
       "          [207.     , 206.     , 211.     ],\n",
       "          [207.     , 206.     , 211.     ],\n",
       "          [207.     , 206.     , 211.     ]],\n",
       " \n",
       "         [[233.3125 , 236.3125 , 245.3125 ],\n",
       "          [233.     , 236.     , 245.     ],\n",
       "          [233.     , 236.     , 245.     ],\n",
       "          ...,\n",
       "          [207.375  , 206.375  , 211.375  ],\n",
       "          [207.375  , 206.375  , 211.375  ],\n",
       "          [207.375  , 206.375  , 211.375  ]],\n",
       " \n",
       "         [[233.83333, 236.83333, 245.83333],\n",
       "          [233.     , 236.     , 245.     ],\n",
       "          [233.     , 236.     , 245.     ],\n",
       "          ...,\n",
       "          [208.     , 207.     , 212.     ],\n",
       "          [208.     , 207.     , 212.     ],\n",
       "          [208.     , 207.     , 212.     ]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[196.83333, 196.83333, 196.83333],\n",
       "          [196.     , 196.     , 196.     ],\n",
       "          [196.     , 196.     , 196.     ],\n",
       "          ...,\n",
       "          [235.     , 231.     , 222.     ],\n",
       "          [235.     , 231.     , 222.     ],\n",
       "          [235.     , 231.     , 222.     ]],\n",
       " \n",
       "         [[196.3125 , 196.3125 , 196.3125 ],\n",
       "          [196.     , 196.     , 196.     ],\n",
       "          [196.     , 196.     , 196.     ],\n",
       "          ...,\n",
       "          [234.375  , 230.375  , 221.375  ],\n",
       "          [234.375  , 230.375  , 221.375  ],\n",
       "          [234.375  , 230.375  , 221.375  ]],\n",
       " \n",
       "         [[196.     , 196.     , 196.     ],\n",
       "          [196.     , 196.     , 196.     ],\n",
       "          [195.6875 , 195.6875 , 195.6875 ],\n",
       "          ...,\n",
       "          [234.     , 230.     , 221.     ],\n",
       "          [234.     , 230.     , 221.     ],\n",
       "          [234.     , 230.     , 221.     ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[157.83333, 157.83333, 157.83333],\n",
       "          [157.     , 157.     , 157.     ],\n",
       "          [157.     , 157.     , 157.     ],\n",
       "          ...,\n",
       "          [151.     , 150.     , 145.     ],\n",
       "          [151.     , 150.     , 145.     ],\n",
       "          [151.     , 150.     , 145.     ]],\n",
       " \n",
       "         [[157.83333, 157.83333, 157.83333],\n",
       "          [157.     , 157.     , 157.     ],\n",
       "          [157.     , 157.     , 157.     ],\n",
       "          ...,\n",
       "          [151.     , 150.     , 145.     ],\n",
       "          [151.     , 150.     , 145.     ],\n",
       "          [151.     , 150.     , 145.     ]],\n",
       " \n",
       "         [[157.83333, 157.83333, 157.83333],\n",
       "          [157.     , 157.     , 157.     ],\n",
       "          [157.     , 157.     , 157.     ],\n",
       "          ...,\n",
       "          [151.     , 150.     , 145.     ],\n",
       "          [151.     , 150.     , 145.     ],\n",
       "          [151.     , 150.     , 145.     ]]],\n",
       " \n",
       " \n",
       "        [[[194.     , 192.     , 179.     ],\n",
       "          [194.     , 192.     , 179.     ],\n",
       "          [194.     , 192.     , 179.     ],\n",
       "          ...,\n",
       "          [148.     , 144.     , 133.     ],\n",
       "          [148.     , 144.     , 133.     ],\n",
       "          [148.     , 144.     , 133.     ]],\n",
       " \n",
       "         [[194.     , 192.     , 179.     ],\n",
       "          [194.     , 192.     , 179.     ],\n",
       "          [194.     , 192.     , 179.     ],\n",
       "          ...,\n",
       "          [148.     , 144.     , 133.     ],\n",
       "          [148.     , 144.     , 133.     ],\n",
       "          [148.     , 144.     , 133.     ]],\n",
       " \n",
       "         [[194.     , 192.     , 179.     ],\n",
       "          [194.     , 192.     , 179.     ],\n",
       "          [194.     , 192.     , 179.     ],\n",
       "          ...,\n",
       "          [147.625  , 143.625  , 132.625  ],\n",
       "          [147.625  , 143.625  , 132.625  ],\n",
       "          [147.625  , 143.625  , 132.625  ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[254.     , 254.     , 244.     ],\n",
       "          [254.     , 254.     , 244.     ],\n",
       "          [254.     , 254.     , 244.     ],\n",
       "          ...,\n",
       "          [121.     , 117.     , 106.     ],\n",
       "          [121.     , 117.     , 106.     ],\n",
       "          [120.16666, 116.16666, 105.16666]],\n",
       " \n",
       "         [[254.375  , 254.375  , 244.375  ],\n",
       "          [254.375  , 254.375  , 244.375  ],\n",
       "          [254.375  , 254.375  , 244.375  ],\n",
       "          ...,\n",
       "          [121.     , 117.     , 106.     ],\n",
       "          [121.     , 117.     , 106.     ],\n",
       "          [120.16666, 116.16666, 105.16666]],\n",
       " \n",
       "         [[255.     , 255.     , 245.     ],\n",
       "          [255.     , 255.     , 245.     ],\n",
       "          [255.     , 255.     , 245.     ],\n",
       "          ...,\n",
       "          [121.     , 117.     , 106.     ],\n",
       "          [121.     , 117.     , 106.     ],\n",
       "          [120.16666, 116.16666, 105.16666]]],\n",
       " \n",
       " \n",
       "        [[[223.83333, 227.83333, 238.83333],\n",
       "          [223.     , 227.     , 238.     ],\n",
       "          [223.     , 227.     , 238.     ],\n",
       "          ...,\n",
       "          [193.     , 197.     , 208.     ],\n",
       "          [193.     , 197.     , 208.     ],\n",
       "          [193.     , 197.     , 208.     ]],\n",
       " \n",
       "         [[223.3125 , 227.3125 , 238.3125 ],\n",
       "          [223.     , 227.     , 238.     ],\n",
       "          [223.     , 227.     , 238.     ],\n",
       "          ...,\n",
       "          [193.     , 197.     , 208.     ],\n",
       "          [193.     , 197.     , 208.     ],\n",
       "          [193.     , 197.     , 208.     ]],\n",
       " \n",
       "         [[223.     , 227.     , 238.     ],\n",
       "          [223.     , 227.     , 238.     ],\n",
       "          [222.6875 , 226.6875 , 237.6875 ],\n",
       "          ...,\n",
       "          [193.     , 197.     , 208.     ],\n",
       "          [193.     , 197.     , 208.     ],\n",
       "          [193.     , 197.     , 208.     ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[205.27083, 215.52083, 221.89583],\n",
       "          [205.0625 , 214.3125 , 221.1875 ],\n",
       "          [205.0625 , 212.27083, 220.16667],\n",
       "          ...,\n",
       "          [158.     , 160.     , 172.     ],\n",
       "          [158.     , 160.     , 172.     ],\n",
       "          [158.     , 160.     , 172.     ]],\n",
       " \n",
       "         [[204.83333, 215.83333, 221.83333],\n",
       "          [204.5    , 214.5    , 221.     ],\n",
       "          [205.     , 212.33333, 220.16667],\n",
       "          ...,\n",
       "          [158.     , 160.     , 172.     ],\n",
       "          [158.     , 160.     , 172.     ],\n",
       "          [158.     , 160.     , 172.     ]],\n",
       " \n",
       "         [[204.83333, 215.83333, 221.83333],\n",
       "          [204.5    , 214.5    , 221.     ],\n",
       "          [205.     , 212.33333, 220.16667],\n",
       "          ...,\n",
       "          [158.     , 160.     , 172.     ],\n",
       "          [158.     , 160.     , 172.     ],\n",
       "          [158.     , 160.     , 172.     ]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
       " array([4, 2, 2, 0, 0, 4, 1, 3, 2, 2, 1, 2, 0, 1, 0, 0, 4, 2, 4, 3, 1, 0,\n",
       "        1, 2, 0, 1, 3, 3, 1, 4, 3, 1], dtype=int32)>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OverfittingCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if logs.get('accuracy') > 0.999:\n",
    "      self.model.stop_training = True\n",
    "      print('Trying to prevent overfitting - stopping training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "WHpMx4BE4fVB"
   },
   "outputs": [],
   "source": [
    "# Just placing everything in a class to make analysis easier\n",
    "class TrashClassifer():\n",
    "    \n",
    "    def __init__(self, home_path='/home/sarp/DS5460', main_dir='garbage_classifier', model_name='vgg16', crop=False):\n",
    "        # Define some constants\n",
    "        self.HOME = Path(home_path)\n",
    "        self.MAIN_DIR = self.HOME / main_dir #the main directory of this project to include all the data\n",
    "        \n",
    "        # Data augmentation switch\n",
    "        self.crop = crop\n",
    "        \n",
    "        crop_string = 'crop' if self.crop else 'no_crop'\n",
    "        \n",
    "\n",
    "\n",
    "        self.TEST_PATH = self.MAIN_DIR / 'test'\n",
    "        self.TRAIN_PATH = self.MAIN_DIR / 'train'\n",
    "\n",
    "        #TensorBoard - log model statistics\n",
    "        self.LOGDIR = self.MAIN_DIR / 'my_logs'\n",
    "        \n",
    "        self.MODEL_DIR = self.MAIN_DIR / 'models'\n",
    "        \n",
    "        self.BASE_URL = 'https://raw.githubusercontent.com/hoganj15/Waste_Image_Classifier/main/images_multiclass'\n",
    "        \n",
    "        self.set_up()\n",
    "        \n",
    "        # some tricks to load models by name\n",
    "        from inspect import getmembers, isfunction\n",
    "        self.available_models = {o[0].lower():o[1]for o in getmembers(keras.applications) if isfunction(o[1])}\n",
    "        \n",
    "        model_module = importlib.import_module('keras.applications' + '.' + model_name)\n",
    "        self.preprocess(model_module.preprocess_input)\n",
    "        self.model_path = self.MODEL_DIR / (model_name + '_' + crop_string)\n",
    "        if self.model_path.exists():\n",
    "            print('Model exists, not training.')\n",
    "            self.model = tf.keras.models.load_model(self.model_path)\n",
    "        \n",
    "        else:\n",
    "            model_instantiator = self.available_models[model_name.replace('_','')]\n",
    "            self.train(model_instantiator, weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "        \n",
    "        self.test_model()\n",
    "    \n",
    "    def get_run_logdir(self):\n",
    "        run_id = time.strftime('run_%Y_%m_%d-%H_%M_%S')\n",
    "        return self.LOGDIR / run_id\n",
    "\n",
    "    \n",
    "    def set_up(self):\n",
    "        if not self.TEST_PATH.exists():\n",
    "            self.TEST_PATH.mkdir(parents=True)\n",
    "        if not self.TRAIN_PATH.exists():\n",
    "              self.TRAIN_PATH.mkdir(parents=True)\n",
    "        #reading in the files required for image imports\n",
    "\n",
    "        test_csv_path = self.TEST_PATH / 'test_files.csv'       \n",
    "        if not test_csv_path.exists():\n",
    "            r = requests.get(self.BASE_URL + '/' + test_csv_path.name)\n",
    "            test_csv_path.write_text(r.text)\n",
    "        \n",
    "        \n",
    "        train_csv_path = self.TRAIN_PATH / pathlib.Path('train_files.csv')\n",
    "        if not train_csv_path.exists():\n",
    "            r = requests.get(self.BASE_URL + '/' + train_csv_path.name)\n",
    "            train_csv_path.write_text(r.text)\n",
    "\n",
    "        file_names = pd.read_csv(test_csv_path)\n",
    "        for label in file_names.label.unique().tolist():\n",
    "            label_path = self.TEST_PATH / label\n",
    "            if not label_path.exists():\n",
    "                label_path.mkdir() #create a folder for each class in the test directory\n",
    "            files_to_read = file_names[file_names['label'] == label] #filter the files to read for that folder\n",
    "            if len(list(label_path.iterdir())) < len(files_to_read): \n",
    "                for file_name in files_to_read['file_name'].tolist():\n",
    "                    url = self.BASE_URL + '/' + 'test' + '/' + label + '/' + file_name\n",
    "                    r = requests.get(url)\n",
    "                    file_path = label_path / file_name\n",
    "                    file_path.write_bytes(r.content)\n",
    "   \n",
    "        file_names = pd.read_csv(train_csv_path)\n",
    "        for label in file_names.label.unique().tolist():\n",
    "            label_path = self.TRAIN_PATH / label\n",
    "            if not label_path.exists():\n",
    "                label_path.mkdir() #create a folder for each class in the train directory\n",
    "            files_to_read = file_names[file_names['label'] == label] #filter the files to read for that folder\n",
    "            if len(list(label_path.iterdir())) < len(files_to_read): #only read in images if they aren't already there\n",
    "                for file_name in files_to_read['file_name'].tolist():\n",
    "                    url = self.BASE_URL + '/' + 'train' + '/' + label + '/' + file_name\n",
    "                    r = requests.get(url)\n",
    "                    file_path = label_path / file_name\n",
    "                    file_path.write_bytes(r.content)\n",
    "                    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def preprocess(self, preprocess_function):\n",
    "        print(preprocess_function)\n",
    "        original_size = (512, 384)\n",
    "        target_size = (224, 224)\n",
    "        batch_size = 32\n",
    "        #process = partial(process_img, crop=self.crop)\n",
    "        \n",
    "        # resize, rescale, random crop and random flip\n",
    "        # Set preprocessing based on the crop switch above\n",
    "        \n",
    "        if self.crop:\n",
    "            preprocessing = tf.keras.Sequential([\n",
    "                keras.layers.Resizing(*target_size),\n",
    "                #keras.layers.Rescaling(1./255),\n",
    "                keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "                keras.layers.RandomCrop(*target_size),\n",
    "            ])\n",
    "        \n",
    "        else:\n",
    "            preprocessing = tf.keras.Sequential([\n",
    "                keras.layers.Resizing(*target_size),\n",
    "                #keras.layers.Rescaling(1./255),\n",
    "            ])\n",
    "        \n",
    "        folder_names = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
    "        \n",
    "        train_ds = image.image_dataset_from_directory(\n",
    "            '/home/sarp/DS5460/garbage_classifier/train/',\n",
    "            validation_split=0.2,\n",
    "            subset='training',\n",
    "            seed=123,\n",
    "            image_size=original_size,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "\n",
    "        val_ds = image.image_dataset_from_directory(\n",
    "            '/home/sarp/DS5460/garbage_classifier/train/',\n",
    "            validation_split=0.2,\n",
    "            subset='validation',\n",
    "            seed=123,\n",
    "            image_size=original_size,\n",
    "            batch_size=batch_size,            \n",
    "        )\n",
    "\n",
    "        test_ds = image.image_dataset_from_directory(\n",
    "            '/home/sarp/DS5460/garbage_classifier/test/',\n",
    "            seed=123,\n",
    "            image_size=original_size,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "        self.train_ds = train_ds.map(lambda x, y: (preprocess_function(preprocessing(x)), y))\n",
    "        self.val_ds = test_ds.map(lambda x, y: (preprocess_function(preprocessing(x)), y))\n",
    "        self.test_ds = test_ds.map(lambda x, y: (preprocess_function(preprocessing(x)), y))\n",
    "        \n",
    "    def train(self, transfer_model, **kwargs):\n",
    "        base_model = transfer_model(**kwargs)\n",
    "        \n",
    "        run_logdir = self.get_run_logdir()\n",
    "        tensorboard_callback = keras.callbacks.TensorBoard(run_logdir, update_freq=\"epoch\")\n",
    "\n",
    "        #freeze the base model \n",
    "        base_model.trainable = False\n",
    "\n",
    "        #define the type of NN architecture - sequential model specifies a linear stack of layers \n",
    "        model = keras.models.Sequential()\n",
    "\n",
    "        #add the pre-trained model\n",
    "        model.add(base_model)\n",
    "\n",
    "        #pool layer to prepare data as input into dense layer \n",
    "        model.add(keras.layers.GlobalAveragePooling2D())\n",
    "        model.add(keras.layers.Dense(256, activation='relu'))\n",
    "        #batch normalization layer re-centers and re-scales the network - helps accelerate training\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        #dropout layer - temporarily deactivates 20% of the nodes in the network each epoch to redistribute weights/help network concentrate on \"weak\" features and prevent overfitting\n",
    "        model.add(keras.layers.Dropout(0.2))\n",
    "        #flatten layer to single array for input into dense layer \n",
    "        model.add(keras.layers.Flatten())\n",
    "        # prediction layer - 6 neurons = 6 category outputs, and softmax to normalize the output of the network to a probability distribution over the predicted output classes \n",
    "        model.add(keras.layers.Dense(6, activation='softmax'))\n",
    "        #compile model, specify sparse categorical crossentropy for classification and evaluate accuracy\n",
    "        model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        #train model for 40 epochs \n",
    "        history = model.fit(self.train_ds, epochs=40, validation_data = self.val_ds, callbacks = [keras.callbacks.EarlyStopping(patience=3, monitor='val_loss'), OverfittingCallback(), tensorboard_callback])\n",
    "        #unfreeze base model \n",
    "        base_model.trainable = True\n",
    "        model.summary()\n",
    "        history = model.fit(self.train_ds, epochs=40, validation_data=self.val_ds, callbacks=[keras.callbacks.EarlyStopping(patience=1, monitor='val_loss'), OverfittingCallback()])\n",
    "        model.save(self.model_path)\n",
    "        self.model = model\n",
    "        \n",
    "    def class_convert(self, classess):\n",
    "        pred=[]\n",
    "        for i in classess:\n",
    "            if i ==0:\n",
    "                pred.append('Cardboard')\n",
    "            elif i==1:\n",
    "                pred.append('Glass')\n",
    "            elif i==2:\n",
    "                pred.append('Metal')\n",
    "            elif i==3:\n",
    "                pred.append('Paper')\n",
    "            elif i==4:\n",
    "                pred.append('Plastic')\n",
    "            elif i==5:\n",
    "                pred.append('Trash')\n",
    "        return pred\n",
    "\n",
    "    def test_model(self):        \n",
    "        result = self.model.evaluate(self.test_ds)\n",
    "        dict(zip(self.model.metrics_names, result))\n",
    "        \n",
    "        self.model.summary()\n",
    "\n",
    "    \n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for batch_x, batch_y in self.test_ds:\n",
    "            y_true.append(batch_y)\n",
    "            \n",
    "            preds = self.model.predict(batch_x)\n",
    "            y_pred.append(np.argmax(preds, axis=-1))\n",
    "            \n",
    "        correct_labels = tf.concat([item for item in y_true], axis = 0).numpy()\n",
    "        predicted_labels = tf.concat([item for item in y_pred], axis = 0).numpy()\n",
    "\n",
    "        \n",
    "        correct = (correct_labels == predicted_labels).sum()\n",
    "        incorrect = (correct_labels != predicted_labels).sum()\n",
    "        print(f\"Accuracy {correct/(correct+incorrect)}\")\n",
    "\n",
    "        cm=confusion_matrix(correct_labels, predicted_labels)\n",
    "        df_cm = pd.DataFrame(cm, range(cm.shape[0]), range(cm.shape[1]))\n",
    "        df_cm.columns = ['Cardboard','Glass','Metal','Paper','Plastic','Trash']\n",
    "        df_cm.index = ['Cardboard','Glass','Metal','Paper','Plastic','Trash']\n",
    "\n",
    "        fig = plt.subplots(figsize=size_)\n",
    "        sb.set(font_scale=1)\n",
    "        sb.heatmap(df_cm, annot=True, annot_kws={\"size\": 10}, cmap=\"viridis\") # font size\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dSg2bQMhg_i9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function preprocess_input at 0x7f76cfd90d30>\n",
      "Found 2009 files belonging to 6 classes.\n",
      "Using 1608 files for training.\n",
      "Found 2009 files belonging to 6 classes.\n",
      "Using 401 files for validation.\n",
      "Found 518 files belonging to 6 classes.\n",
      "Model exists, not training.\n",
      "14/17 [=======================>......] - ETA: 1s - loss: 0.4373 - accuracy: 0.8616"
     ]
    }
   ],
   "source": [
    "classifier = TrashClassifer(model_name='mobilenet', crop=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xJopAWmXnuS2"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7juzYwDSo2N-"
   },
   "source": [
    "## Step 6: Generate Predictions & View Model Results\n",
    "\n",
    "####6.1: View Incorrect Predictions\n",
    "First, let's look at the predictions that were classified incorrectly. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_convert(classess):\n",
    "    pred=[]\n",
    "    for i in classess:\n",
    "        if i ==0:\n",
    "            pred.append('Cardboard')\n",
    "        elif i==1:\n",
    "            pred.append('Glass')\n",
    "        elif i==2:\n",
    "            pred.append('Metal')\n",
    "        elif i==3:\n",
    "            pred.append('Paper')\n",
    "        elif i==4:\n",
    "            pred.append('Plastic')\n",
    "        elif i==5:\n",
    "            pred.append('Trash')\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-4DvyB7U8rj2"
   },
   "outputs": [],
   "source": [
    "def test_model(model_path):\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    incorrect = dict()\n",
    "    for idx, predictions in enumerate(model.predict(X_test)):\n",
    "      if np.argmax(predictions) != y_test[idx][0]:\n",
    "        incorrect[idx] = {'Predicted': np.argmax(predictions), 'Actual': y_test[idx][0]}\n",
    "\n",
    "    incorrect_preds = pd.DataFrame.from_dict(incorrect, orient='index')\n",
    "    incorrect_preds.reset_index()\n",
    "    #generate predictions using the test dataset\n",
    "    predicted_class=np.argmax(model.predict(X_test), axis = -1)\n",
    "    predicted_class\n",
    "    corr=0\n",
    "    false=0\n",
    "    for i in range(len(y_test)):\n",
    "        if y_test[i]==predicted_class[i]:\n",
    "             corr=corr+1\n",
    "        else:\n",
    "            false=false+1\n",
    "\n",
    "    print(\"Correct:\",corr)\n",
    "    print(\"False\",false)\n",
    "    print(\"accuracy:\", corr / (false+corr))\n",
    "\n",
    "    pred_class=class_convert(predicted_class)\n",
    "    y_class=class_convert(y_test)\n",
    "\n",
    "    cm=confusion_matrix(y_class,pred_class)\n",
    "    df_cm = pd.DataFrame(cm, range(cm.shape[0]), range(cm.shape[1]))\n",
    "    df_cm.columns = ['Cardboard','Glass','Metal','Paper','Plastic','Trash']\n",
    "    df_cm.index = ['Cardboard','Glass','Metal','Paper','Plastic','Trash']\n",
    "\n",
    "    fig = plt.subplots(figsize=size_)\n",
    "    sb.set(font_scale=1)\n",
    "    sb.heatmap(df_cm, annot=True, annot_kws={\"size\": 10}, cmap=\"viridis\") # font size\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2R0dJrfpccC"
   },
   "source": [
    "\n",
    "####6.2: Visualize Predictions \n",
    "Since the CNN classifier is only capable of generating numerical predictions from 0-5, we can now generate predictions and then assign them back to their associated garbage class. After doing so, we can plot each image, its true label, and compare this to the predicted label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xLxLIJOSdv_G"
   },
   "outputs": [],
   "source": [
    "#plot the image from the test dataset, the predicted garbage label, and the actual garbage label\n",
    "\n",
    "L=7\n",
    "W=7\n",
    "fig,axes=plt.subplots(L,W,figsize=(17,17))\n",
    "axes=axes.ravel()\n",
    "\n",
    "for i in np.arange(0,L*W):\n",
    "    axes[i].imshow(X_test[i])\n",
    "    if pred_class[i] == y_class[i]:\n",
    "      axes[i].set_title('Prediction={}\\n True={}'.format(pred_class[i],y_class[i]), color='C2')\n",
    "    else: \n",
    "      axes[i].set_title('Prediction={}\\n True={}'.format(pred_class[i],y_class[i]), color='C3')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.subplots_adjust(wspace=2,hspace=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
